{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read txt files into lists for train and test data\n",
    "import glob\n",
    "import os\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "def cleanMe(html):\n",
    "    \n",
    "    soup = BeautifulSoup(html, \"lxml\") # create a new bs4 object from the html data loaded\n",
    "    for script in soup([\"script\", \"style\"]): # remove all javascript and stylesheet code\n",
    "        script.extract()\n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "neg_list = sorted(glob.glob(os.path.join(os.getcwd(), \"train_neg\", \"*.txt\")))\n",
    "pos_list = sorted(glob.glob(os.path.join(os.getcwd(), \"train_pos\", \"*.txt\")))\n",
    "neg_testlist = sorted(glob.glob(os.path.join(os.getcwd(), \"test_neg\", \"*.txt\")))\n",
    "pos_testlist = sorted(glob.glob(os.path.join(os.getcwd(), \"test_pos\", \"*.txt\")))\n",
    "\n",
    "neg_train = []\n",
    "pos_train = []\n",
    "neg_test = []\n",
    "pos_test = []\n",
    "\n",
    "for file_path in neg_list:\n",
    "    with open(file_path) as f_input:\n",
    "        neg_train.append(cleanMe(f_input.read()))\n",
    "\n",
    "for file_path in pos_list:\n",
    "    with open(file_path) as f_input:\n",
    "        pos_train.append(cleanMe(f_input.read()))\n",
    "        \n",
    "for file_path in neg_testlist:\n",
    "    with open(file_path) as f_input:\n",
    "        neg_test.append(cleanMe(f_input.read()))\n",
    "\n",
    "for file_path in pos_testlist:\n",
    "    with open(file_path) as f_input:\n",
    "        pos_test.append(cleanMe(f_input.read()))\n",
    "\n",
    "train_list = neg_train + pos_train\n",
    "test_list = neg_test + pos_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n",
      "/Users/huyucong/Desktop/hw1/train_neg/0_3.txt\n",
      "Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_train))\n",
    "print(len(pos_train))\n",
    "print(neg_list[0])\n",
    "print(neg_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# Split train data into actual train and validation sets\n",
    "\n",
    "train_split = 10000\n",
    "train_data = neg_train[:train_split] + pos_train[:train_split]\n",
    "train_targets = [0] * len(neg_train[:train_split]) + [1] * len(pos_train[:train_split])\n",
    "\n",
    "val_data = neg_train[train_split:] + pos_train[train_split:]\n",
    "val_targets = [0] * len(neg_train[train_split:]) + [1] * len(pos_train[train_split:])\n",
    "\n",
    "test_data = test_list\n",
    "test_targets = [0] * len(neg_test) + [1] * len(pos_test)\n",
    "\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print(train_targets[9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Trek Hidden Frontier will surprise you in many ways. First, it's a fan made series, available only on the web, and it features mainly friends & neighbors who have the computer programs and home video cameras and sewing machines to, as Mickey & Judy once put it, put on a show. It's definitely friends & neighbors to, you can tell. A lot of these people aren't the most beautiful looking folks you've ever seen, or the youngest, or the thinnest\n",
      "some of them stumble through their lines like they're walking on marbles\n",
      "some of them have thick accents, or simply don't seem to speak well in the first place, whick makes it virtually impossible to understand a single solitary word that they're saying. Still, you have to admit, for everything these friends & neighbors have put together, it's actually fun to watch. Yes, some of the dialogue is hokey. Yes, it's a little odd (though admittedly a little cool too) watching two Starfleet males kiss (although some of the kissing scenes seem to go on and on.) Yes, you cringe a bit when they clearly quote from ST:TOS, TNG, other shows and the movies, or when you hear the theme from Galaxy Quest played at the beginning and end of every show. Okay. We can get by that. Why? The graphics are first rate. Better than almost anything you've seen. And sometimes, a show or two really stands out story-wise\n",
      "some of them are actually real tear-jerkers.Hidden Frontier is a total guilty pleasure in every sense of the word\n",
      "but you have to give the people involved credit where credit is due. It takes a lot of effort to put on a production of this magnitude. People, sets, costumes, graphics\n",
      "it's a huge effort on a lot of people's parts. We watch, we return, and we thank them.\n"
     ]
    }
   ],
   "source": [
    "# Random sample from train dataset\n",
    "import random\n",
    "print (train_data[random.randint(0, len(train_data) - 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the classifier, first we are going to tokenize the dataset using spacy.io\n",
    "\n",
    "Run (shown in the cell below):\n",
    "\n",
    "* ```pip install spacy```\n",
    "* ```python -m spacy download en_core_web_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/huyucong/anaconda3/lib/python3.6/site-packages (2.0.12)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (1.14.3)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: regex==2017.4.5 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (2017.4.5)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (6.10.3)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (1.31.2)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from spacy) (0.28.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.4.16)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.4.1)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.25.0)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /Users/huyucong/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/huyucong/anaconda3/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /Users/huyucong/anaconda3/lib/python3.6/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOCTYPE HTML', 'My yardstick', 'yardstick for', 'for measuring', 'measuring a', 'a movie', \"movie 's\", \"'s watch\", 'ability is', 'is if', 'if I', 'I get', 'get squirmy', 'If I', 'I start', 'start shifting', 'shifting positions', 'positions and', 'and noticing', 'noticing my', 'my butt', 'butt is', 'is sore', 'the film', 'film is', 'is too', 'too long', 'This movie', 'movie did', 'did not', 'not even', 'even come', 'come close', 'close to', 'to being', 'being boring', 'Predictable in', 'in some', 'some parts', 'parts sure', 'but never', 'never boring.<br', 'boring.<br /><br', '/><br />All', '/>All of', 'of the', 'the other', 'other military', 'military branches', 'branches have', 'have had', 'had love', 'love notes', 'notes written', 'written about', 'about them', 'them and', 'and seen', 'seen their', 'their recruitment', 'recruitment levels', 'levels go', 'go up', 'why not', 'not the', 'the Coast', 'Coast Guard', 'Guard too', 'They are', 'are definitely', 'definitely under', 'until the', 'the day', 'day your', 'your boat', 'boat sinks', 'sinks that', 'that is.<br', 'is.<br /><br', '/><br />The', '/>The movie', 'movie was', 'was very', 'very enjoyable', 'enjoyable and', 'and fun', 'Kevin Costner', 'Costner is', 'is perfect', 'perfect as', 'as the', 'the aging', 'aging macho', 'macho man', 'man who', 'who does', \"does n't\", \"n't know\", 'know when', 'when to', 'to quit', 'I was', 'was most', 'most impressed', 'impressed by', 'by Ashton', 'Ashton Kutcher', \"Kutcher 's\", \"'s performance\"]\n"
     ]
    }
   ],
   "source": [
    "# Let's write the tokenization function \n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "    tokens = tokenizer(sent)\n",
    "    output = []\n",
    "    for index in range(0,len(tokens)-1):\n",
    "        if tokens[index].text not in punctuations and tokens[index+1].text not in punctuations:\n",
    "            output.append(tokens[index].text+' '+tokens[index+1].text)\n",
    "    return output\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(u\"<!DOCTYPE HTML>\\n<head>My yardstick for measuring a movie's watch-ability is if I get squirmy. If I start shifting positions and noticing my butt is sore, the film is too long. This movie did not even come close to being boring. Predictable in some parts sure, but never boring.<br /><br />All of the other military branches have had love notes written about them and seen their recruitment levels go up, why not the Coast Guard too? They are definitely under-appreciated, until the day your boat sinks that is.<br /><br />The movie was very enjoyable and fun. Kevin Costner is perfect as the aging macho man who doesn't know when to quit. However, I was most impressed by Ashton Kutcher's performance. \")\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n",
      "Tokenizing test data\n",
      "Tokenizing train data\n"
     ]
    }
   ],
   "source": [
    "# This is the code cell that tokenizes train/val/test datasets\n",
    "# However it takes about 15-20 minutes to run it\n",
    "# For convinience we have provided the preprocessed datasets\n",
    "# Please see the next code cell\n",
    "import pickle as pkl\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset \n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "# val set tokens\n",
    "print (\"Tokenizing val data\")\n",
    "val_data_tokens, _ = tokenize_dataset(val_data)\n",
    "pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# test set tokens\n",
    "print (\"Tokenizing test data\")\n",
    "test_data_tokens, _ = tokenize_dataset(test_data)\n",
    "pkl.dump(test_data_tokens, open(\"test_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "train_data_tokens, all_train_tokens = tokenize_dataset(train_data)\n",
    "pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 4146552\n"
     ]
    }
   ],
   "source": [
    "# First, download datasets from here\n",
    "# Use your NYU account\n",
    "#https://drive.google.com/open?id=1eR2LFI5MGliHlaL1S2nsX4ouIO1k_ip2\n",
    "#https://drive.google.com/open?id=133QCWbiz_Xc7Qm4r6t-fJP1K669xjNlM\n",
    "#https://drive.google.com/open?id=1SuUIUpJ1iznU707ktkpnEGSwt_XIqOYp\n",
    "#https://drive.google.com/open?id=1UQsrZ2LVfcxdxxa47344fMs_qvya72KR\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "# Then, load preprocessed train, val and test datasets\n",
    "train_data_tokens = pkl.load(open(\"train_data_tokens.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"all_train_tokens.p\", \"rb\"))\n",
    "\n",
    "val_data_tokens = pkl.load(open(\"val_data_tokens.p\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"test_data_tokens.p\", \"rb\"))\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens)))\n",
    "\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create the vocabulary of most common 10,000 tokens in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of the': 2,\n",
       " 'in the': 3,\n",
       " 'is a': 4,\n",
       " 'this movie': 5,\n",
       " 'and the': 6,\n",
       " 'to be': 7,\n",
       " 'to the': 8,\n",
       " 'the film': 9,\n",
       " \"it 's\": 10,\n",
       " 'the movie': 11,\n",
       " 'this film': 12,\n",
       " 'in a': 13,\n",
       " 'on the': 14,\n",
       " 'of a': 15,\n",
       " 'for the': 16,\n",
       " 'with the': 17,\n",
       " 'one of': 18,\n",
       " \"do n't\": 19,\n",
       " 'it is': 20,\n",
       " 'it was': 21,\n",
       " 'is the': 22,\n",
       " 'as a': 23,\n",
       " 'at the': 24,\n",
       " \"It 's\": 25,\n",
       " 'with a': 26,\n",
       " 'from the': 27,\n",
       " 'in this': 28,\n",
       " 'as the': 29,\n",
       " 'I was': 30,\n",
       " 'to see': 31,\n",
       " 'out of': 32,\n",
       " 'this is': 33,\n",
       " 'that the': 34,\n",
       " 'This is': 35,\n",
       " 'movie is': 36,\n",
       " 'was a': 37,\n",
       " \"does n't\": 38,\n",
       " 'I have': 39,\n",
       " 'and I': 40,\n",
       " 'by the': 41,\n",
       " 'have been': 42,\n",
       " 'for a': 43,\n",
       " \"I 'm\": 44,\n",
       " 'of this': 45,\n",
       " \"did n't\": 46,\n",
       " 'film is': 47,\n",
       " 'and a': 48,\n",
       " 'is not': 49,\n",
       " 'the first': 50,\n",
       " 'the story': 51,\n",
       " \"'s a\": 52,\n",
       " 'if you': 53,\n",
       " 'all the': 54,\n",
       " 'the same': 55,\n",
       " 'the end': 56,\n",
       " 'a good': 57,\n",
       " \"ca n't\": 58,\n",
       " 'a lot': 59,\n",
       " 'but it': 60,\n",
       " 'that it': 61,\n",
       " 'the most': 62,\n",
       " 'I do': 63,\n",
       " 'and it': 64,\n",
       " 'of his': 65,\n",
       " 'to make': 66,\n",
       " 'It is': 67,\n",
       " 'on a': 68,\n",
       " 'about the': 69,\n",
       " 'to watch': 70,\n",
       " 'a movie': 71,\n",
       " \"I 've\": 72,\n",
       " \"is n't\": 73,\n",
       " 'the best': 74,\n",
       " 'that I': 75,\n",
       " 'If you': 76,\n",
       " 'I think': 77,\n",
       " 'that is': 78,\n",
       " 'This movie': 79,\n",
       " 'to a': 80,\n",
       " 'a great': 81,\n",
       " 'be a': 82,\n",
       " 'this one': 83,\n",
       " 'a very': 84,\n",
       " 'but I': 85,\n",
       " 'a few': 86,\n",
       " 'there is': 87,\n",
       " 'to get': 88,\n",
       " 'but the': 89,\n",
       " 'have to': 90,\n",
       " 'would have': 91,\n",
       " 'was the': 92,\n",
       " 'I would': 93,\n",
       " 'want to': 94,\n",
       " \"that 's\": 95,\n",
       " 'he is': 96,\n",
       " 'has a': 97,\n",
       " 'a little': 98,\n",
       " 'is that': 99,\n",
       " 'to do': 100,\n",
       " 'into the': 101,\n",
       " 'lot of': 102,\n",
       " 'like a': 103,\n",
       " 'is one': 104,\n",
       " 'some of': 105,\n",
       " 'as well': 106,\n",
       " 'the characters': 107,\n",
       " 'would be': 108,\n",
       " 'a film': 109,\n",
       " 'I am': 110,\n",
       " 'kind of': 111,\n",
       " 'have a': 112,\n",
       " \"was n't\": 113,\n",
       " 'the way': 114,\n",
       " 'they are': 115,\n",
       " \"'s not\": 116,\n",
       " 'to have': 117,\n",
       " \"he 's\": 118,\n",
       " 'that he': 119,\n",
       " 'the other': 120,\n",
       " 'at least': 121,\n",
       " 'I can': 122,\n",
       " 'It was': 123,\n",
       " 'trying to': 124,\n",
       " 'The film': 125,\n",
       " 'that this': 126,\n",
       " 'movie was': 127,\n",
       " 'a bit': 128,\n",
       " 'and his': 129,\n",
       " 'I did': 130,\n",
       " 'is an': 131,\n",
       " 'in his': 132,\n",
       " 'which is': 133,\n",
       " 'more than': 134,\n",
       " 'the plot': 135,\n",
       " 'could have': 136,\n",
       " 'the only': 137,\n",
       " 'I had': 138,\n",
       " 'at all': 139,\n",
       " 'there are': 140,\n",
       " 'the time': 141,\n",
       " 'going to': 142,\n",
       " 'of it': 143,\n",
       " \"there 's\": 144,\n",
       " 'the original': 145,\n",
       " 'to say': 146,\n",
       " 'who is': 147,\n",
       " 'he was': 148,\n",
       " 'by a': 149,\n",
       " 'the worst': 150,\n",
       " 'There is': 151,\n",
       " 'you can': 152,\n",
       " 'the whole': 153,\n",
       " 'of them': 154,\n",
       " \"you 're\": 155,\n",
       " 'like the': 156,\n",
       " 'such a': 157,\n",
       " 'and that': 158,\n",
       " 'I could': 159,\n",
       " 'not a': 160,\n",
       " 'There are': 161,\n",
       " 'of all': 162,\n",
       " 'seems to': 163,\n",
       " 'most of': 164,\n",
       " 'I saw': 165,\n",
       " 'into a': 166,\n",
       " 'The movie': 167,\n",
       " 'is so': 168,\n",
       " 'like this': 169,\n",
       " 'This film': 170,\n",
       " 'is just': 171,\n",
       " 'you have': 172,\n",
       " 'fact that': 173,\n",
       " 'part of': 174,\n",
       " 'as it': 175,\n",
       " 'the world': 176,\n",
       " 'that they': 177,\n",
       " 'and then': 178,\n",
       " 'all of': 179,\n",
       " 'with his': 180,\n",
       " 'for this': 181,\n",
       " 'I thought': 182,\n",
       " 'has been': 183,\n",
       " \"'s the\": 184,\n",
       " 'you are': 185,\n",
       " 'is very': 186,\n",
       " 'because it': 187,\n",
       " 'this was': 188,\n",
       " 'the fact': 189,\n",
       " 'from a': 190,\n",
       " 'they were': 191,\n",
       " 'had a': 192,\n",
       " 'of her': 193,\n",
       " \"could n't\": 194,\n",
       " 'and is': 195,\n",
       " 'of course': 196,\n",
       " 'the show': 197,\n",
       " 'through the': 198,\n",
       " 'it to': 199,\n",
       " 'and he': 200,\n",
       " 'over the': 201,\n",
       " \"n't have\": 202,\n",
       " \"n't know\": 203,\n",
       " 'at a': 204,\n",
       " 'that was': 205,\n",
       " 'in my': 206,\n",
       " 'but this': 207,\n",
       " 'will be': 208,\n",
       " 'so much': 209,\n",
       " 'be the': 210,\n",
       " 'of my': 211,\n",
       " 'The story': 212,\n",
       " 'film was': 213,\n",
       " 'rest of': 214,\n",
       " 'can be': 215,\n",
       " 'supposed to': 216,\n",
       " 'she is': 217,\n",
       " 'should be': 218,\n",
       " 'to find': 219,\n",
       " 'the rest': 220,\n",
       " 'the director': 221,\n",
       " 'about this': 222,\n",
       " 'when the': 223,\n",
       " 'story is': 224,\n",
       " 'does not': 225,\n",
       " 'sort of': 226,\n",
       " 'it a': 227,\n",
       " \"'ve seen\": 228,\n",
       " 'to go': 229,\n",
       " 'movie that': 230,\n",
       " 'about a': 231,\n",
       " 'the main': 232,\n",
       " 'that you': 233,\n",
       " 'ever seen': 234,\n",
       " 'is no': 235,\n",
       " \"n't even\": 236,\n",
       " 'the acting': 237,\n",
       " \"I 'd\": 238,\n",
       " 'I ca': 239,\n",
       " 'with this': 240,\n",
       " 'The only': 241,\n",
       " 'it would': 242,\n",
       " 'see the': 243,\n",
       " 'just a': 244,\n",
       " 'the two': 245,\n",
       " 'can not': 246,\n",
       " 'to this': 247,\n",
       " 'to his': 248,\n",
       " 'the audience': 249,\n",
       " 'when I': 250,\n",
       " 'was not': 251,\n",
       " 'the actors': 252,\n",
       " 'has to': 253,\n",
       " 'such as': 254,\n",
       " 'film that': 255,\n",
       " 'hard to': 256,\n",
       " 'able to': 257,\n",
       " 'he has': 258,\n",
       " 'because of': 259,\n",
       " \"wo n't\": 260,\n",
       " 'the last': 261,\n",
       " 'is in': 262,\n",
       " 'make a': 263,\n",
       " 'is also': 264,\n",
       " 'The acting': 265,\n",
       " 'up to': 266,\n",
       " 'each other': 267,\n",
       " 'had to': 268,\n",
       " 'it does': 269,\n",
       " 'say that': 270,\n",
       " 'In the': 271,\n",
       " 'acting is': 272,\n",
       " 'I found': 273,\n",
       " 'in which': 274,\n",
       " \"she 's\": 275,\n",
       " 'than the': 276,\n",
       " 'the book': 277,\n",
       " 'and you': 278,\n",
       " 'of their': 279,\n",
       " 'it has': 280,\n",
       " 'have seen': 281,\n",
       " 'see it': 282,\n",
       " 'see this': 283,\n",
       " 'very good': 284,\n",
       " 'when he': 285,\n",
       " 'should have': 286,\n",
       " 'seem to': 287,\n",
       " 'end of': 288,\n",
       " 'in it': 289,\n",
       " 'not the': 290,\n",
       " 'did not': 291,\n",
       " 'and this': 292,\n",
       " 'watch it': 293,\n",
       " 'of those': 294,\n",
       " 'enough to': 295,\n",
       " \"There 's\": 296,\n",
       " 'there was': 297,\n",
       " 'well as': 298,\n",
       " 'with her': 299,\n",
       " 'on this': 300,\n",
       " 'in their': 301,\n",
       " 'as I': 302,\n",
       " \"'s just\": 303,\n",
       " 'watch this': 304,\n",
       " 'up with': 305,\n",
       " 'as an': 306,\n",
       " 'and they': 307,\n",
       " 'back to': 308,\n",
       " 'special effects': 309,\n",
       " 'I really': 310,\n",
       " 'about it': 311,\n",
       " 'a bad': 312,\n",
       " 'and not': 313,\n",
       " 'not to': 314,\n",
       " 'played by': 315,\n",
       " 'the cast': 316,\n",
       " 'are a': 317,\n",
       " 'for me': 318,\n",
       " 'when it': 319,\n",
       " 'in an': 320,\n",
       " \"you 'll\": 321,\n",
       " 'movie and': 322,\n",
       " 'that she': 323,\n",
       " 'you want': 324,\n",
       " 'the script': 325,\n",
       " 'of an': 326,\n",
       " 'where the': 327,\n",
       " 'you will': 328,\n",
       " 'The plot': 329,\n",
       " 'tries to': 330,\n",
       " 'to take': 331,\n",
       " 'a big': 332,\n",
       " 'are the': 333,\n",
       " 'story of': 334,\n",
       " 'I know': 335,\n",
       " 'I just': 336,\n",
       " 'was so': 337,\n",
       " 'are not': 338,\n",
       " 'to me': 339,\n",
       " \"film 's\": 340,\n",
       " 'better than': 341,\n",
       " 'a couple': 342,\n",
       " \"they 're\": 343,\n",
       " 'is about': 344,\n",
       " 'too much': 345,\n",
       " 'who has': 346,\n",
       " 'so many': 347,\n",
       " 'you do': 348,\n",
       " 'that are': 349,\n",
       " 'piece of': 350,\n",
       " 'a man': 351,\n",
       " 'as he': 352,\n",
       " \"would n't\": 353,\n",
       " 'sense of': 354,\n",
       " 'fan of': 355,\n",
       " 'and there': 356,\n",
       " 'in all': 357,\n",
       " 'if it': 358,\n",
       " 'based on': 359,\n",
       " 'during the': 360,\n",
       " 'this show': 361,\n",
       " 'the entire': 362,\n",
       " 'his own': 363,\n",
       " 'wanted to': 364,\n",
       " 'film and': 365,\n",
       " 'after the': 366,\n",
       " 'and even': 367,\n",
       " 'been a': 368,\n",
       " 'I mean': 369,\n",
       " 'of these': 370,\n",
       " 'try to': 371,\n",
       " 'think that': 372,\n",
       " 'the viewer': 373,\n",
       " 'do not': 374,\n",
       " 'people who': 375,\n",
       " 'characters are': 376,\n",
       " 'she was': 377,\n",
       " 'in her': 378,\n",
       " 'have the': 379,\n",
       " 'I watched': 380,\n",
       " 'out to': 381,\n",
       " 'the beginning': 382,\n",
       " 'but not': 383,\n",
       " \"n't get\": 384,\n",
       " 'saw this': 385,\n",
       " 'for his': 386,\n",
       " 'the one': 387,\n",
       " 'I love': 388,\n",
       " 'it all': 389,\n",
       " 'could be': 390,\n",
       " 'a real': 391,\n",
       " 'and her': 392,\n",
       " 'get the': 393,\n",
       " 'as if': 394,\n",
       " \"Do n't\": 395,\n",
       " 'not be': 396,\n",
       " 'a young': 397,\n",
       " 'the very': 398,\n",
       " 'couple of': 399,\n",
       " 'was just': 400,\n",
       " 'so I': 401,\n",
       " 'because the': 402,\n",
       " \"'m not\": 403,\n",
       " 'was in': 404,\n",
       " 'watching this': 405,\n",
       " 'make it': 406,\n",
       " 'lack of': 407,\n",
       " 'with an': 408,\n",
       " \"I 'll\": 409,\n",
       " 'but he': 410,\n",
       " 'like it': 411,\n",
       " 'for it': 412,\n",
       " 'of what': 413,\n",
       " 'and in': 414,\n",
       " 'instead of': 415,\n",
       " \"n't really\": 416,\n",
       " 'plot is': 417,\n",
       " 'what the': 418,\n",
       " 'to give': 419,\n",
       " 'I guess': 420,\n",
       " 'way to': 421,\n",
       " 'but that': 422,\n",
       " 'when they': 423,\n",
       " 'than a': 424,\n",
       " 'not only': 425,\n",
       " 'up in': 426,\n",
       " 'it in': 427,\n",
       " 'I will': 428,\n",
       " 'it and': 429,\n",
       " 'to her': 430,\n",
       " \"are n't\": 431,\n",
       " 'This was': 432,\n",
       " \"n't be\": 433,\n",
       " 'if the': 434,\n",
       " 'need to': 435,\n",
       " \"n't think\": 436,\n",
       " 'out the': 437,\n",
       " 'for her': 438,\n",
       " 'get a': 439,\n",
       " 'have ever': 440,\n",
       " 'between the': 441,\n",
       " 'as they': 442,\n",
       " 'version of': 443,\n",
       " \"'s character\": 444,\n",
       " 'what I': 445,\n",
       " \"That 's\": 446,\n",
       " 'is to': 447,\n",
       " 'of that': 448,\n",
       " 'in love': 449,\n",
       " 'the screen': 450,\n",
       " 'those who': 451,\n",
       " 'even though': 452,\n",
       " 'of its': 453,\n",
       " 'with some': 454,\n",
       " 'much of': 455,\n",
       " 'look at': 456,\n",
       " 'that there': 457,\n",
       " 'and she': 458,\n",
       " 'because I': 459,\n",
       " 'they have': 460,\n",
       " 'much more': 461,\n",
       " 'like to': 462,\n",
       " 'very well': 463,\n",
       " 'wants to': 464,\n",
       " 'on his': 465,\n",
       " 'any of': 466,\n",
       " 'the character': 467,\n",
       " 'a story': 468,\n",
       " 'full of': 469,\n",
       " 'of 10': 470,\n",
       " 'Of course': 471,\n",
       " 'and was': 472,\n",
       " \"have n't\": 473,\n",
       " 'but they': 474,\n",
       " 'when you': 475,\n",
       " 'the series': 476,\n",
       " 'in that': 477,\n",
       " 'looks like': 478,\n",
       " 'his wife': 479,\n",
       " 'he does': 480,\n",
       " 'may be': 481,\n",
       " 'was very': 482,\n",
       " 'we are': 483,\n",
       " 'who are': 484,\n",
       " 'the ending': 485,\n",
       " 'the people': 486,\n",
       " 'and some': 487,\n",
       " 'see a': 488,\n",
       " 'not even': 489,\n",
       " 'to it': 490,\n",
       " 'up the': 491,\n",
       " 'looking for': 492,\n",
       " 'is still': 493,\n",
       " 'we have': 494,\n",
       " 'what it': 495,\n",
       " 'the next': 496,\n",
       " 'to show': 497,\n",
       " 'at times': 498,\n",
       " 'what is': 499,\n",
       " 'or the': 500,\n",
       " 'movie to': 501,\n",
       " 'New York': 502,\n",
       " 'think it': 503,\n",
       " 'a long': 504,\n",
       " 'In fact': 505,\n",
       " 'is really': 506,\n",
       " 'due to': 507,\n",
       " 'One of': 508,\n",
       " 'off the': 509,\n",
       " 'it for': 510,\n",
       " 'and all': 511,\n",
       " 'know what': 512,\n",
       " 'if they': 513,\n",
       " 'they do': 514,\n",
       " 'to keep': 515,\n",
       " 'away from': 516,\n",
       " 'that a': 517,\n",
       " 'the real': 518,\n",
       " 'him to': 519,\n",
       " 'the point': 520,\n",
       " 'of time': 521,\n",
       " 'bit of': 522,\n",
       " 'has the': 523,\n",
       " 'that has': 524,\n",
       " 'And the': 525,\n",
       " 'to know': 526,\n",
       " 'a new': 527,\n",
       " 'in fact': 528,\n",
       " 'rather than': 529,\n",
       " 'I like': 530,\n",
       " 'But the': 531,\n",
       " 'give it': 532,\n",
       " 'He is': 533,\n",
       " 'go to': 534,\n",
       " 'had been': 535,\n",
       " 'get to': 536,\n",
       " \"'ve ever\": 537,\n",
       " 'movie I': 538,\n",
       " 'much better': 539,\n",
       " 'the scene': 540,\n",
       " 'waste of': 541,\n",
       " 'along with': 542,\n",
       " 'first time': 543,\n",
       " 'movie with': 544,\n",
       " 'that we': 545,\n",
       " 'a woman': 546,\n",
       " 'film has': 547,\n",
       " 'it on': 548,\n",
       " 'are all': 549,\n",
       " 'are so': 550,\n",
       " 'used to': 551,\n",
       " 'bunch of': 552,\n",
       " 'was made': 553,\n",
       " 'the second': 554,\n",
       " 'had the': 555,\n",
       " 'must have': 556,\n",
       " 'throughout the': 557,\n",
       " 'and so': 558,\n",
       " 'being a': 559,\n",
       " 'their own': 560,\n",
       " 'for some': 561,\n",
       " 'the title': 562,\n",
       " 'more of': 563,\n",
       " 'with it': 564,\n",
       " 'who was': 565,\n",
       " 'make the': 566,\n",
       " 'the top': 567,\n",
       " 'many of': 568,\n",
       " 'the DVD': 569,\n",
       " 'is quite': 570,\n",
       " 'might be': 571,\n",
       " 'time to': 572,\n",
       " 'film to': 573,\n",
       " 'made me': 574,\n",
       " 'a small': 575,\n",
       " 'man who': 576,\n",
       " 'how to': 577,\n",
       " 'you know': 578,\n",
       " 'as much': 579,\n",
       " 'when she': 580,\n",
       " 'movie has': 581,\n",
       " 'the music': 582,\n",
       " 'which I': 583,\n",
       " 'me to': 584,\n",
       " 'seen in': 585,\n",
       " 'in some': 586,\n",
       " 'the camera': 587,\n",
       " 'so bad': 588,\n",
       " 'character is': 589,\n",
       " 'my opinion': 590,\n",
       " 'of people': 591,\n",
       " 'one is': 592,\n",
       " 'up and': 593,\n",
       " 'the right': 594,\n",
       " 'what they': 595,\n",
       " \"who 's\": 596,\n",
       " 'time and': 597,\n",
       " 'in its': 598,\n",
       " 'is more': 599,\n",
       " 'was an': 600,\n",
       " 'all that': 601,\n",
       " 'do with': 602,\n",
       " 'lots of': 603,\n",
       " 'a nice': 604,\n",
       " 'which was': 605,\n",
       " 'recommend this': 606,\n",
       " \"n't like\": 607,\n",
       " 'going on': 608,\n",
       " 'the role': 609,\n",
       " 'but in': 610,\n",
       " 'the old': 611,\n",
       " 'even the': 612,\n",
       " 'that would': 613,\n",
       " 'years ago': 614,\n",
       " 'believe that': 615,\n",
       " 'and more': 616,\n",
       " 'and has': 617,\n",
       " 'was one': 618,\n",
       " 'use of': 619,\n",
       " 'read the': 620,\n",
       " 'point of': 621,\n",
       " \"you 've\": 622,\n",
       " 'how the': 623,\n",
       " 'It has': 624,\n",
       " 'even if': 625,\n",
       " 'to come': 626,\n",
       " 'in order': 627,\n",
       " 'I felt': 628,\n",
       " 'minutes of': 629,\n",
       " 'know that': 630,\n",
       " 'if he': 631,\n",
       " 'it as': 632,\n",
       " 'a fan': 633,\n",
       " 'no one': 634,\n",
       " 'As a': 635,\n",
       " \"He 's\": 636,\n",
       " 'not have': 637,\n",
       " 'watching it': 638,\n",
       " 'acting was': 639,\n",
       " 'has no': 640,\n",
       " 'watch the': 641,\n",
       " 'order to': 642,\n",
       " 'with no': 643,\n",
       " 'can see': 644,\n",
       " 'the final': 645,\n",
       " '... and': 646,\n",
       " 'The first': 647,\n",
       " 'is what': 648,\n",
       " 'for all': 649,\n",
       " 'the great': 650,\n",
       " 'might have': 651,\n",
       " 'my favorite': 652,\n",
       " \"n't make\": 653,\n",
       " 'and their': 654,\n",
       " 'may have': 655,\n",
       " 'story and': 656,\n",
       " 'think the': 657,\n",
       " 'what he': 658,\n",
       " 'a better': 659,\n",
       " 'the action': 660,\n",
       " 'as to': 661,\n",
       " 'low budget': 662,\n",
       " 'a bunch': 663,\n",
       " \"'s no\": 664,\n",
       " 'the man': 665,\n",
       " 'you get': 666,\n",
       " 'to kill': 667,\n",
       " 'we see': 668,\n",
       " 'movie for': 669,\n",
       " 'are some': 670,\n",
       " 'around the': 671,\n",
       " 'and we': 672,\n",
       " 'even more': 673,\n",
       " 'and have': 674,\n",
       " 'on DVD': 675,\n",
       " 'where he': 676,\n",
       " 'think of': 677,\n",
       " 'love with': 678,\n",
       " 'of film': 679,\n",
       " 'to play': 680,\n",
       " 'type of': 681,\n",
       " 'it seems': 682,\n",
       " 'it did': 683,\n",
       " 'look like': 684,\n",
       " 'a huge': 685,\n",
       " 'because he': 686,\n",
       " 'film with': 687,\n",
       " 'I loved': 688,\n",
       " 'manages to': 689,\n",
       " 'watched it': 690,\n",
       " 'they had': 691,\n",
       " 'but there': 692,\n",
       " 'a whole': 693,\n",
       " 'it just': 694,\n",
       " 'year old': 695,\n",
       " 'same time': 696,\n",
       " 'there were': 697,\n",
       " 'you like': 698,\n",
       " 'good movie': 699,\n",
       " 'main character': 700,\n",
       " 'attempt to': 701,\n",
       " 'it could': 702,\n",
       " 'seemed to': 703,\n",
       " 'pretty much': 704,\n",
       " 'to look': 705,\n",
       " 'have no': 706,\n",
       " 'from this': 707,\n",
       " 'to tell': 708,\n",
       " 'also a': 709,\n",
       " 'for an': 710,\n",
       " 'group of': 711,\n",
       " 'you see': 712,\n",
       " 'I liked': 713,\n",
       " 'he can': 714,\n",
       " 'and an': 715,\n",
       " 'the scenes': 716,\n",
       " 'like that': 717,\n",
       " 'thought it': 718,\n",
       " 'to believe': 719,\n",
       " 'must be': 720,\n",
       " 'because they': 721,\n",
       " 'the more': 722,\n",
       " 'his life': 723,\n",
       " 'and one': 724,\n",
       " 'ever made': 725,\n",
       " 'good as': 726,\n",
       " 'the middle': 727,\n",
       " 'I got': 728,\n",
       " 'back in': 729,\n",
       " 'the past': 730,\n",
       " '... I': 731,\n",
       " 'nothing to': 732,\n",
       " 'he had': 733,\n",
       " 'out there': 734,\n",
       " 'a way': 735,\n",
       " 'I also': 736,\n",
       " 'up for': 737,\n",
       " 'is going': 738,\n",
       " 'she has': 739,\n",
       " 'to think': 740,\n",
       " 'and how': 741,\n",
       " 'film in': 742,\n",
       " 'makes it': 743,\n",
       " 'idea of': 744,\n",
       " 'to work': 745,\n",
       " 'they did': 746,\n",
       " 'does a': 747,\n",
       " 'decided to': 748,\n",
       " 'number of': 749,\n",
       " 'just as': 750,\n",
       " 'is it': 751,\n",
       " 'an excellent': 752,\n",
       " 'tried to': 753,\n",
       " 'come to': 754,\n",
       " 'if I': 755,\n",
       " 'a really': 756,\n",
       " 'seen it': 757,\n",
       " 'and to': 758,\n",
       " 'the big': 759,\n",
       " 'for that': 760,\n",
       " 'the greatest': 761,\n",
       " 'is good': 762,\n",
       " 'example of': 763,\n",
       " 'pretty good': 764,\n",
       " 'in one': 765,\n",
       " \"n't want\": 766,\n",
       " 'but a': 767,\n",
       " 'all time': 768,\n",
       " 'I must': 769,\n",
       " 'for you': 770,\n",
       " 'and very': 771,\n",
       " 'is all': 772,\n",
       " 'and what': 773,\n",
       " 'or not': 774,\n",
       " \"'ve been\": 775,\n",
       " 'made a': 776,\n",
       " 'the bad': 777,\n",
       " 'comes to': 778,\n",
       " 'who have': 779,\n",
       " 'I feel': 780,\n",
       " 'thing that': 781,\n",
       " 'is pretty': 782,\n",
       " 'a pretty': 783,\n",
       " 'or a': 784,\n",
       " 'or even': 785,\n",
       " 'as good': 786,\n",
       " 'the family': 787,\n",
       " 'close to': 788,\n",
       " 'a more': 789,\n",
       " 'is great': 790,\n",
       " 'plenty of': 791,\n",
       " 'I still': 792,\n",
       " 'watched this': 793,\n",
       " \"n't a\": 794,\n",
       " 'But it': 795,\n",
       " 'made it': 796,\n",
       " 'he did': 797,\n",
       " 'it had': 798,\n",
       " 'down to': 799,\n",
       " 'was that': 800,\n",
       " 'what a': 801,\n",
       " 'before the': 802,\n",
       " 'to an': 803,\n",
       " 'I hope': 804,\n",
       " 'quite a': 805,\n",
       " 'But I': 806,\n",
       " 'watching the': 807,\n",
       " \"'s all\": 808,\n",
       " 'characters and': 809,\n",
       " 'time I': 810,\n",
       " 'saw it': 811,\n",
       " 'There was': 812,\n",
       " 'is actually': 813,\n",
       " \"what 's\": 814,\n",
       " 'the early': 815,\n",
       " 'him in': 816,\n",
       " 'so that': 817,\n",
       " 'a comedy': 818,\n",
       " 'it will': 819,\n",
       " 'scene where': 820,\n",
       " 'for him': 821,\n",
       " 'them to': 822,\n",
       " 'the house': 823,\n",
       " 'than this': 824,\n",
       " 'anyone who': 825,\n",
       " 'is nothing': 826,\n",
       " 'the good': 827,\n",
       " 'in any': 828,\n",
       " 'her to': 829,\n",
       " 'I remember': 830,\n",
       " 'a chance': 831,\n",
       " 'is as': 832,\n",
       " 'movie in': 833,\n",
       " 'the new': 834,\n",
       " 'the young': 835,\n",
       " 'that will': 836,\n",
       " 'not as': 837,\n",
       " 'on to': 838,\n",
       " 'as one': 839,\n",
       " 'it again': 840,\n",
       " 'was really': 841,\n",
       " 'the idea': 842,\n",
       " 'only one': 843,\n",
       " \"n't see\": 844,\n",
       " \"n't believe\": 845,\n",
       " 'only thing': 846,\n",
       " \"were n't\": 847,\n",
       " 'of your': 848,\n",
       " 'none of': 849,\n",
       " 'was also': 850,\n",
       " 'it with': 851,\n",
       " 'and as': 852,\n",
       " 'other than': 853,\n",
       " 'The characters': 854,\n",
       " 'made the': 855,\n",
       " 'was going': 856,\n",
       " 'your time': 857,\n",
       " 'out in': 858,\n",
       " 'as she': 859,\n",
       " 'saw the': 860,\n",
       " 'scene in': 861,\n",
       " 'give this': 862,\n",
       " 'far as': 863,\n",
       " 'to help': 864,\n",
       " 'is probably': 865,\n",
       " 'has some': 866,\n",
       " 'on screen': 867,\n",
       " 'on her': 868,\n",
       " 'I believe': 869,\n",
       " 'this time': 870,\n",
       " 'place in': 871,\n",
       " 'movies that': 872,\n",
       " 'directed by': 873,\n",
       " 'only a': 874,\n",
       " 'find out': 875,\n",
       " 'the kind': 876,\n",
       " 'until the': 877,\n",
       " 'and just': 878,\n",
       " 'scenes are': 879,\n",
       " 'not just': 880,\n",
       " 'what was': 881,\n",
       " 'In this': 882,\n",
       " 'much as': 883,\n",
       " 'On the': 884,\n",
       " 'with him': 885,\n",
       " 'from his': 886,\n",
       " 'of any': 887,\n",
       " 'for their': 888,\n",
       " 'interested in': 889,\n",
       " 'an old': 890,\n",
       " \"'s an\": 891,\n",
       " 'with their': 892,\n",
       " 'only to': 893,\n",
       " 'movie about': 894,\n",
       " 'may not': 895,\n",
       " 'meant to': 896,\n",
       " 'of how': 897,\n",
       " 'of being': 898,\n",
       " 'be in': 899,\n",
       " 'is only': 900,\n",
       " 'the case': 901,\n",
       " 'that does': 902,\n",
       " 'with all': 903,\n",
       " 'All in': 904,\n",
       " 'a wonderful': 905,\n",
       " 'and over': 906,\n",
       " 'very much': 907,\n",
       " 'can only': 908,\n",
       " 'to my': 909,\n",
       " 'life and': 910,\n",
       " 'as this': 911,\n",
       " \"'s also\": 912,\n",
       " 'makes the': 913,\n",
       " 'his character': 914,\n",
       " \"'m sure\": 915,\n",
       " 'Some of': 916,\n",
       " 'you could': 917,\n",
       " 'high school': 918,\n",
       " 'seen the': 919,\n",
       " 'make this': 920,\n",
       " 'go on': 921,\n",
       " 'real life': 922,\n",
       " 'films that': 923,\n",
       " 'you ca': 924,\n",
       " 'and its': 925,\n",
       " 'him and': 926,\n",
       " 'the opening': 927,\n",
       " 'to mention': 928,\n",
       " 'an hour': 929,\n",
       " 'film for': 930,\n",
       " \"n't help\": 931,\n",
       " 'a true': 932,\n",
       " 'did a': 933,\n",
       " 'what you': 934,\n",
       " 'that makes': 935,\n",
       " 'a decent': 936,\n",
       " 'made in': 937,\n",
       " 'of which': 938,\n",
       " 'up a': 939,\n",
       " 'to their': 940,\n",
       " 'people in': 941,\n",
       " 'set in': 942,\n",
       " 'you think': 943,\n",
       " 'down the': 944,\n",
       " 'could not': 945,\n",
       " 'the day': 946,\n",
       " 'a horror': 947,\n",
       " 'to put': 948,\n",
       " 'of us': 949,\n",
       " 'the girl': 950,\n",
       " 'And I': 951,\n",
       " \"n't seen\": 952,\n",
       " 'even a': 953,\n",
       " 'but she': 954,\n",
       " 'role of': 955,\n",
       " 'on and': 956,\n",
       " 'over and': 957,\n",
       " 'they could': 958,\n",
       " 'good and': 959,\n",
       " 'plays a': 960,\n",
       " 'seen this': 961,\n",
       " 'What a': 962,\n",
       " 'too many': 963,\n",
       " 'got to': 964,\n",
       " 'the guy': 965,\n",
       " 'the lead': 966,\n",
       " 'you would': 967,\n",
       " 'that one': 968,\n",
       " 'horror film': 969,\n",
       " 'really is': 970,\n",
       " 'I never': 971,\n",
       " 'she does': 972,\n",
       " 'a while': 973,\n",
       " 'to understand': 974,\n",
       " 'see how': 975,\n",
       " 'The script': 976,\n",
       " 'to him': 977,\n",
       " 'goes to': 978,\n",
       " 'for those': 979,\n",
       " 'are just': 980,\n",
       " 'it out': 981,\n",
       " 'the part': 982,\n",
       " 'series of': 983,\n",
       " 'and for': 984,\n",
       " 'on it': 985,\n",
       " 'of one': 986,\n",
       " 'you to': 987,\n",
       " 'one that': 988,\n",
       " 'just to': 989,\n",
       " 'to save': 990,\n",
       " 'came out': 991,\n",
       " 'by his': 992,\n",
       " 'but also': 993,\n",
       " 'make you': 994,\n",
       " 'would not': 995,\n",
       " 'chance to': 996,\n",
       " 'film I': 997,\n",
       " \"n't seem\": 998,\n",
       " \"movie 's\": 999,\n",
       " 'after a': 1000,\n",
       " 'way of': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 10000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)\n",
    "token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 8043 ; token a variety\n",
      "Token a variety; token id 8043\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create PyTorch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 170,    1, 6516,  ...,    0,    0,    0],\n",
      "        [   1,  530,    1,  ..., 7243, 1753,  107],\n",
      "        [   1,    1,    1,  ..., 6568,  289,    1],\n",
      "        ...,\n",
      "        [3992,  122, 1234,  ...,    0,    0,    0],\n",
      "        [1461,    1, 1406,  ...,  206,  590,    1],\n",
      "        [  25, 6082,  590,  ...,    0,    0,    0]])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "#train_loader = NewsGroupDataset(train_data_indices, train_targets)\n",
    "#val_loader = NewsGroupDataset(val_data_indices, val_targets)\n",
    "#test_loader = NewsGroupDataset(test_data_indices, test_targets)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = NewsGroupDataset(train_data_indices, train_targets)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = NewsGroupDataset(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = NewsGroupDataset(test_data_indices, test_targets)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "    print (data)\n",
    "    print (labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will define Bag-of-Words model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import torch related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "\n",
    "emb_dim = 100\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [101/625], Validation Acc: 77.6\n",
      "Epoch: [1/10], Step: [201/625], Validation Acc: 77.88\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 78.0\n",
      "Epoch: [1/10], Step: [401/625], Validation Acc: 77.54\n",
      "Epoch: [1/10], Step: [501/625], Validation Acc: 77.98\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 77.78\n",
      "Epoch: [2/10], Step: [101/625], Validation Acc: 77.9\n",
      "Epoch: [2/10], Step: [201/625], Validation Acc: 77.94\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 78.06\n",
      "Epoch: [2/10], Step: [401/625], Validation Acc: 77.9\n",
      "Epoch: [2/10], Step: [501/625], Validation Acc: 77.84\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 77.96\n",
      "Epoch: [3/10], Step: [101/625], Validation Acc: 77.96\n",
      "Epoch: [3/10], Step: [201/625], Validation Acc: 78.06\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 77.88\n",
      "Epoch: [3/10], Step: [401/625], Validation Acc: 78.04\n",
      "Epoch: [3/10], Step: [501/625], Validation Acc: 77.98\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 77.98\n",
      "Epoch: [4/10], Step: [101/625], Validation Acc: 77.98\n",
      "Epoch: [4/10], Step: [201/625], Validation Acc: 77.88\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 77.96\n",
      "Epoch: [4/10], Step: [401/625], Validation Acc: 77.84\n",
      "Epoch: [4/10], Step: [501/625], Validation Acc: 78.02\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 78.04\n",
      "Epoch: [5/10], Step: [101/625], Validation Acc: 77.98\n",
      "Epoch: [5/10], Step: [201/625], Validation Acc: 77.98\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 77.9\n",
      "Epoch: [5/10], Step: [401/625], Validation Acc: 77.76\n",
      "Epoch: [5/10], Step: [501/625], Validation Acc: 77.88\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 77.8\n",
      "Epoch: [6/10], Step: [101/625], Validation Acc: 77.78\n",
      "Epoch: [6/10], Step: [201/625], Validation Acc: 77.54\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 77.72\n",
      "Epoch: [6/10], Step: [401/625], Validation Acc: 77.64\n",
      "Epoch: [6/10], Step: [501/625], Validation Acc: 76.64\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 77.58\n",
      "Epoch: [7/10], Step: [101/625], Validation Acc: 77.62\n",
      "Epoch: [7/10], Step: [201/625], Validation Acc: 77.8\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 77.74\n",
      "Epoch: [7/10], Step: [401/625], Validation Acc: 77.52\n",
      "Epoch: [7/10], Step: [501/625], Validation Acc: 77.78\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 77.84\n",
      "Epoch: [8/10], Step: [101/625], Validation Acc: 77.84\n",
      "Epoch: [8/10], Step: [201/625], Validation Acc: 77.44\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 77.88\n",
      "Epoch: [8/10], Step: [401/625], Validation Acc: 77.36\n",
      "Epoch: [8/10], Step: [501/625], Validation Acc: 77.56\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 77.84\n",
      "Epoch: [9/10], Step: [101/625], Validation Acc: 77.68\n",
      "Epoch: [9/10], Step: [201/625], Validation Acc: 77.76\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 77.78\n",
      "Epoch: [9/10], Step: [401/625], Validation Acc: 77.62\n",
      "Epoch: [9/10], Step: [501/625], Validation Acc: 77.4\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 77.66\n",
      "Epoch: [10/10], Step: [101/625], Validation Acc: 77.6\n",
      "Epoch: [10/10], Step: [201/625], Validation Acc: 77.58\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 77.7\n",
      "Epoch: [10/10], Step: [401/625], Validation Acc: 77.68\n",
      "Epoch: [10/10], Step: [501/625], Validation Acc: 77.8\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 77.78\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training for 10 epochs\n",
      "Val Acc 77.74\n",
      "Test Acc 78.424\n"
     ]
    }
   ],
   "source": [
    "print (\"After training for {} epochs\".format(num_epochs))\n",
    "print (\"Val Acc {}\".format(test_model(val_loader, model)))\n",
    "print (\"Test Acc {}\".format(test_model(test_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1\n",
    "### Try training the model with larger embedding size and for larger number of epochs\n",
    "### Also plot the training curves of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "### Try downloading IMDB Large Movie Review Dataset that is used for Assignment 1 http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "### and tokenize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "### If you have time, after tokenizing the dataset try training Bag-of-Words model on it and report your initial results\n",
    "### on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
